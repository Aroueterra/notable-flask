{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf_v1\n",
    "from segmenter.slicer import Slice\n",
    "start_time = time.time()\n",
    "\n",
    "class ML:\n",
    "    model = ''\n",
    "    \n",
    "    def __init__(self, model, vocabulary,input_dir,image,classification,seq):\n",
    "        self.model=model\n",
    "        self.vocabulary=vocabulary\n",
    "        self.input_dir=input_dir\n",
    "        self.slice_dir=slice_dir\n",
    "        self.classification=classification\n",
    "        self.seq=seq\n",
    "        \n",
    "    def setup(self):\n",
    "        # Read the dictionary\n",
    "        dict_file = open(self.voc_file,'r')\n",
    "        dict_list = dict_file.read().splitlines()\n",
    "        self.int2word = dict()\n",
    "        for word in dict_list:\n",
    "            word_idx = len(int2word)\n",
    "            int2word[word_idx] = word\n",
    "        dict_file.close()\n",
    "        tf.reset_default_graph()\n",
    "        saver = tf_v1.train.import_meta_graph(self.model)\n",
    "        saver.restore(sess,self.model[:-5])\n",
    "        graph = tf_v1.get_default_graph()\n",
    "        self.input = graph.get_tensor_by_name(\"model_input:0\")\n",
    "        self.seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
    "        self.rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "        self.height_tensor = graph.get_tensor_by_name(\"input_height:0\")\n",
    "        self.width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")\n",
    "        self.logits = graph.get_tensor_by_name(\"fully_connected/BiasAdd:0\")\n",
    "        self.decoded, _ = tf_v1.nn.ctc_greedy_decoder(self.logits, self.seq_len)\n",
    "        self.WIDTH_REDUCTION = 16\n",
    "        return self.sess = tf.InteractiveSession()\n",
    "    def predict(self,image,seq_lengths):\n",
    "        slices = Slice(image)\n",
    "        print(\"SLICE COMPLETED in: \" + str(time.time() - start_time) )\n",
    "        prediction = session.run(model.decoded,\n",
    "                          feed_dict={\n",
    "                              self.input: image,\n",
    "                              self.seq_len: seq_lengths,\n",
    "                              self.rnn_keep_prob: 1.0,\n",
    "                          })\n",
    "        print(\"PREDICTION COMPLETED in: \" + str(time.time() - start_time) )\n",
    "        return prediction, slices\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=F size=98x128 at 0x21AEFEDBC10>\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "98\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0131c9f1de79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#img = Image.open(request.files['file'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;31m# str_predictions = sparse_tensor_to_strs(prediction)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# print(str_predictions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Documents\\@ML\\notable-flask\\ml_model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_image, model_image, shape)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;31m#print(test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSlice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SLICE COMPLETED in: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.compat.v1 as tf\n",
    "from segmenter.slicer import Slice\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "import ctc_utils\n",
    "from PIL import ImageDraw\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask,request,send_from_directory,render_template\n",
    "from ml_model import ML\n",
    "import config\n",
    "from apputil import normalize, resize, sparse_tensor_to_strs\n",
    "from matplotlib.pyplot import imshow\n",
    "# GLOBAL ACCESS\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#THIS_FOLDER = os.path.dirname(os.path.abspath(__file__))\n",
    "# SETUP APPLICATION\n",
    "#app = Flask(__name__, static_url_path='')\n",
    "#run_with_ngrok(app)\n",
    "model = ML(config.model,config.voc_file,config.input_dir,\n",
    "           config.slice_dir,config.classification,config.seq)\n",
    "session = model.setup()\n",
    "\n",
    "\n",
    "#f = request.files['file']\n",
    "#read image file string data\n",
    "#filestr = request.files['file'].read()\n",
    "#print(filestr)\n",
    "#convert string data to numpy array\n",
    "IMG_PATH = 'C:/Users/aroue/Downloads/Documents/@ML/Sheet Music/[easy/holynight.png'\n",
    "image_string = open(IMG_PATH, 'rb')\n",
    "#npimg = np.fromstring(image_string, np.uint8)\n",
    "img = Image.open(image_string)\n",
    "img = np.fromfile(image_string, np.uint8)\n",
    "pre_image = cv2.imread(str(IMG_PATH),0)\n",
    "#img = Image.open(request.files['file'])\n",
    "#x = np.frombuffer(buffer(s), dtype='int8')\n",
    "#npimg = normalize(npimg)\n",
    "# convert numpy array to image\n",
    "#img = cv2.imdecode(npimg,cv2.IMREAD_COLOR)IMREAD_UNCHANGED\n",
    "#cvimg = cv2.imdecode(img, cv2.IMREAD_UNCHANGED)\n",
    "pre_image = ctc_utils.resize(pre_image, 128)\n",
    "pre_image = ctc_utils.normalize(pre_image)\n",
    "#model_image = np.asarray(pre_image).reshape(1,pre_image.shape[0],-1,1)\n",
    "shape = model_image.shape[2]\n",
    "input_image = Image.fromarray(pre_image)\n",
    "#if im.mode != 'RGB':\n",
    "    #im = im.convert('RGB')\n",
    "#im.save('img/out.png')\n",
    "#im.show()\n",
    "%matplotlib inline\n",
    "#pil_im = Image.open('data/empire.jpg', 'r')\n",
    "#imshow(np.asarray(im))\n",
    "\n",
    "#imshow(image)\n",
    "#image = np.asarray(cvimg).reshape(1,cvimg.shape[0],-1,1)\n",
    "#image = np.asarray(cvimg).reshape(1,cvimg.shape[0],cvimg.shape[1],1)    \n",
    "#img = Image.open(request.files['file'])\n",
    "\n",
    "prediction, slices = model.predict(input_image, model_image, shape)\n",
    "# str_predictions = sparse_tensor_to_strs(prediction)\n",
    "# print(str_predictions)\n",
    "#         array_of_notes = []\n",
    "#         for w in str_predictions[0]:\n",
    "#             array_of_notes.append(model.int2word[w])\n",
    "#         notes=[]\n",
    "#         for i in array_of_notes:\n",
    "#             if i[0:5]==\"note-\":\n",
    "#                 if not i[6].isdigit():\n",
    "#                     notes.append(i[5:7])\n",
    "#                 else:\n",
    "#                     notes.append(i[5])\n",
    "#         img = Image.open(img).convert('L')\n",
    "#         size = (img.size[0], int(img.size[1]*1.5))\n",
    "#         layer = Image.new('RGB', size, (255,255,255))\n",
    "#         layer.paste(img, box=None)\n",
    "#         img_arr = np.array(layer)\n",
    "#         height = int(img_arr.shape[0])\n",
    "#         width = int(img_arr.shape[1])\n",
    "#         print(img_arr.shape[0])\n",
    "#         draw = ImageDraw.Draw(layer)\n",
    "#         # font = ImageFont.truetype(<font-file>, <font-size>)\n",
    "#         font = ImageFont.truetype(\"Aaargh.ttf\", 16)\n",
    "#         # draw.text((x, y),\"Sample Text\",(r,g,b))\n",
    "#         j = width / 9\n",
    "#         for i in notes:\n",
    "#             draw.text((j, height-40), i, (0,0,0), font=font)\n",
    "#             j+= (width / (len(notes) + 4))\n",
    "#         layer.save(\"img/annotated.png\")\n",
    "#         return render_template('result.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods = ['GET', 'POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        print(\"POST SUCCESS\")\n",
    "        if 'file' not in request.files:\n",
    "            print(\"FILE DOES NOT EXIST\")\n",
    "            return \"No file part in request\", 400\n",
    "        f = request.files['file']\n",
    "        \n",
    "        print(\"READING FILE\")\n",
    "        if f.filename == '':\n",
    "            print(\"No selected file\")\n",
    "            return \"No selected file\", 400\n",
    "        if f and allowed_file(file.filename):\n",
    "            print(\"PREDICTING FILE\")\n",
    "            f.save(os.path.join(app.config['UPLOAD_FOLDER'], f.filename))\n",
    "            img = Image.open(request.files['file'].stream).convert('RGB')\n",
    "            np_img = np.array(img)\n",
    "            cv_img = cv2.cvtColor(np_img, cv2.COLOR_RGB2BGR)\n",
    "            all_predictions = model.predict(cv_img)\n",
    "            generateWAV(all_predictions, \"false\")\n",
    "            print(\"PREDICTION COMPLETE\")\n",
    "            return redirect(url_for('uploaded_file', filename=f.filename))\n",
    "        else:\n",
    "            print(\"FORMAT FAILURE\")\n",
    "    else:\n",
    "        return 'EXIT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def compress(output_filename, dir_name):\n",
    "    shutil.make_archive(output_filename, 'zip', dir_name)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    compress('data/compressed/archive','data/melody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #return fl.send_file(\n",
    "            #data,\n",
    "            #mimetype='application/zip',\n",
    "            #as_attachment=True,\n",
    "            #attachment_filename='data/compressed/archive.zip'\n",
    "            #)\n",
    "            #return redirect(url_for('uploaded_file', filename=f.filename))\n",
    "            \n",
    "                    #for v in request.values:\n",
    "        #    print(v)\n",
    "#         if 'file_name' not in request.files:\n",
    "#             app.logger.error('An error occurred')\n",
    "#         else:\n",
    "#             fn = request.files['file_name']\n",
    "#             print(fn.filename)\n",
    "#             print(str(fn))\n",
    "\n",
    "# @app.route('/predict', methods = ['GET', 'POST'])\n",
    "# def predict():\n",
    "#     if request.method == 'POST':\n",
    "#         #READ INPUT\n",
    "#         if 'file' not in request.files:\n",
    "#             flash('No files')\n",
    "#             return 'Maybe send a file?'\n",
    "#             #return redirect(request.url)\n",
    "#         f = request.files['file']\n",
    "#         if f:\n",
    "#             img = Image.open(request.files['file'].stream).convert('RGB')\n",
    "#             np_img = np.array(img)\n",
    "#             cv_img = cv2.cvtColor(np_img, cv2.COLOR_RGB2BGR)\n",
    "#             all_predictions = model.predict(cv_img)\n",
    "#             generateWAV(all_predictions, \"false\")\n",
    "#         return render_template('result.html')\n",
    "#     return render_template('result.html')\n",
    "\n",
    "# x = \"some data you want to return\"\n",
    "# return x, 200, {'Content-Type': 'text/css; charset=utf-8'}\n",
    "\n",
    "# from flask import Response\n",
    "# r = Response(response=\"TEST OK\", status=200, mimetype=\"application/xml\")\n",
    "# r.headers[\"Content-Type\"] = \"text/xml; charset=utf-8\"\n",
    "# return r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
